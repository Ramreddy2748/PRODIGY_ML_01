# -*- coding: utf-8 -*-
"""linear_regression_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11phdEZxKb1n3CzTGFfzKskMyJJKERRcB
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv(r"/content/train.csv")
df

test_df=pd.read_csv(r'/content/test.csv')
test_df

"""## Exploratory Data Analysis (EDA)"""

df.head()

df.shape

df.info()

df.describe()

df.isna().sum()

# Display the total count of missing values in the entire DataFrame
df.isna().sum().sum()

df.nunique()

plt.figure(figsize=(6, 4))
sns.histplot(df['SalePrice'], bins=30, kde=True)
plt.title('Distribution of SalePrice')
plt.xlabel('SalePrice')
plt.ylabel('Frequency')
plt.show()

"""## Data Preprocessing"""

numerical_columns = df.select_dtypes(include=[np.number]).columns
df[numerical_columns] = df[numerical_columns].apply(lambda x: x.fillna(x.mean()))

important_num_columns = ['MSSubClass', 'LotFrontage', 'MasVnrArea', 'LotArea', 'TotalBsmtSF', 'SalePrice']
correlation_matrix = df[important_num_columns].corr()

plt.figure(figsize=(6, 4))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap for Some Numerical Columns')
plt.show()

sns.pairplot(df[important_num_columns])
plt.show()

categorical_columns = df.select_dtypes(include=['object', 'category']).columns
print(categorical_columns)

sns.scatterplot(data=df, x="OverallQual", y="SalePrice")

mean_prices = df.groupby('OverallQual')['SalePrice'].mean()
max_prices = df.groupby('OverallQual')['SalePrice'].max()
min_prices = df.groupby('OverallQual')['SalePrice'].min()

plt.plot(min_prices, color='red', linestyle='-', linewidth=2, label="Min Price Trend")
plt.plot(mean_prices, color='blue', linestyle='-', linewidth=2, label="Mean Price Trend")
plt.plot(max_prices, color='green', linestyle='-', linewidth=2, label="Max Price Trend")

plt.title('Overall Quality vs Sale Price with Mean and Max Trends')
plt.xlabel('Overall Quality')
plt.ylabel('Sale Price')
plt.legend()

plt.show()

"""## Model Training and Evaluation

Linear Regression Model
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

# Split the data into features (X) and the target variable (y)
X = df.drop(['SalePrice'], axis=1)
y = df[['SalePrice']]

# Split the dataset into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

# Model Evaluation
train_predictions = model.predict(X_train)
val_predictions = model.predict(X_val)

train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))
val_rmse = np.sqrt(mean_squared_error(y_val, val_predictions))

# Print the RMSE values
print("Training RMSE:", train_rmse)
print("Validation RMSE:", val_rmse)

"""## Visualize Predictions"""

plt.figure(figsize=(6, 4))
sns.scatterplot(x=(y_val['SalePrice']), y=(val_predictions[:, 0]))
plt.plot([0, max(np.expm1(y_val['SalePrice']))], [0, max(np.expm1(y_val['SalePrice']))],
         color='black', linestyle='--')
plt.xlabel('Actual SalePrice')
plt.ylabel('Predicted SalePrice')
plt.title('Actual vs Predicted SalePrice')
plt.show()